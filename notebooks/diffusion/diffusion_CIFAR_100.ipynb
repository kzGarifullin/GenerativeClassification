{
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 17525,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 14583
        }
      ],
      "dockerImageVersionId": 30665,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Dffusion model on CIFAR-10**\n",
        "\n",
        "By Katherine Crowson (https://github.com/crowsonkb, https://twitter.com/RiversHaveWings).\n",
        "\n",
        "The model is a denoising diffusion probabilistic model (https://arxiv.org/abs/2006.11239), which is trained to reverse a gradual noising process, allowing the model to generate samples from the learned data distribution starting from random noise. DDIM-style deterministic sampling (https://arxiv.org/abs/2010.02502) is also supported. This model is also trained on continuous timesteps parameterized by the log SNR on each timestep (see Variational Diffusion Models, https://arxiv.org/abs/2107.00630), allowing different noise schedules than the one used during training to be easily used during sampling. It uses the 'v' objective from Progressive Distillation for Fast Sampling of Diffusion Models (https://openreview.net/forum?id=TIdIXIpzhoI) for better conditioned denoised images at high noise levels, but reweights the loss function so that it has the same relative weighting as the 'eps' objective."
      ],
      "metadata": {
        "id": "Dh0w6Isp26ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Licensed under the MIT License\n",
        "\n",
        "# Copyright (c) 2021 Katherine Crowson\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE."
      ],
      "metadata": {
        "id": "TAUwPLG92r89",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the GPU type\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "M99bmqIPyw_Q",
        "execution": {
          "iopub.status.busy": "2024-03-18T08:29:45.783612Z",
          "iopub.execute_input": "2024-03-18T08:29:45.784368Z",
          "iopub.status.idle": "2024-03-18T08:29:46.833860Z",
          "shell.execute_reply.started": "2024-03-18T08:29:45.784337Z",
          "shell.execute_reply": "2024-03-18T08:29:46.832637Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Library imports**"
      ],
      "metadata": {
        "id": "rT74f813drWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyDrive"
      ],
      "metadata": {
        "id": "e3xsliqG8LoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from contextlib import contextmanager\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from torch import optim, nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torchvision.transforms import functional as TF\n",
        "from tqdm.notebook import tqdm, trange"
      ],
      "metadata": {
        "id": "9w5A9GHfynNT",
        "execution": {
          "iopub.status.busy": "2024-03-18T08:48:21.387308Z",
          "iopub.execute_input": "2024-03-18T08:48:21.388046Z",
          "iopub.status.idle": "2024-03-18T08:48:27.558332Z",
          "shell.execute_reply.started": "2024-03-18T08:48:21.388015Z",
          "shell.execute_reply": "2024-03-18T08:48:27.557442Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "wf3G_scm8NtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Utility functions**"
      ],
      "metadata": {
        "id": "o6UdcT99d8YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@contextmanager\n",
        "def train_mode(model, mode=True):\n",
        "    \"\"\"A context manager that places a model into training mode and restores\n",
        "    the previous mode on exit.\"\"\"\n",
        "    modes = [module.training for module in model.modules()]\n",
        "    try:\n",
        "        yield model.train(mode)\n",
        "    finally:\n",
        "        for i, module in enumerate(model.modules()):\n",
        "            module.training = modes[i]\n",
        "def eval_mode(model):\n",
        "    \"\"\"A context manager that places a model into evaluation mode and restores\n",
        "    the previous mode on exit.\"\"\"\n",
        "    return train_mode(model, False)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ema_update(model, averaged_model, decay):\n",
        "    \"\"\"Incorporates updated model parameters into an exponential moving averaged\n",
        "    version of a model. It should be called after each optimizer step.\"\"\"\n",
        "    model_params = dict(model.named_parameters())\n",
        "    averaged_params = dict(averaged_model.named_parameters())\n",
        "    assert model_params.keys() == averaged_params.keys()\n",
        "\n",
        "    for name, param in model_params.items():\n",
        "        averaged_params[name].mul_(decay).add_(param, alpha=1 - decay)\n",
        "\n",
        "    model_buffers = dict(model.named_buffers())\n",
        "    averaged_buffers = dict(averaged_model.named_buffers())\n",
        "    assert model_buffers.keys() == averaged_buffers.keys()\n",
        "\n",
        "    for name, buf in model_buffers.items():\n",
        "        averaged_buffers[name].copy_(buf)"
      ],
      "metadata": {
        "id": "s8IFYM8fy5h8",
        "execution": {
          "iopub.status.busy": "2024-03-18T08:48:31.014471Z",
          "iopub.execute_input": "2024-03-18T08:48:31.015501Z",
          "iopub.status.idle": "2024-03-18T08:48:31.025208Z",
          "shell.execute_reply.started": "2024-03-18T08:48:31.015460Z",
          "shell.execute_reply": "2024-03-18T08:48:31.024208Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model definition**\n",
        "residual U-Net"
      ],
      "metadata": {
        "id": "5LOZ9TPoilxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, main, skip=None):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(*main)\n",
        "        self.skip = skip if skip else nn.Identity()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input) + self.skip(input)\n",
        "\n",
        "\n",
        "class ResConvBlock(ResidualBlock):\n",
        "    def __init__(self, c_in, c_mid, c_out, dropout_last=True):\n",
        "        skip = None if c_in == c_out else nn.Conv2d(c_in, c_out, 1, bias=False)\n",
        "        super().__init__([\n",
        "            nn.Conv2d(c_in, c_mid, 3, padding=1),\n",
        "            nn.Dropout2d(0.1, inplace=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(c_mid, c_out, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ], skip)"
      ],
      "metadata": {
        "id": "YsdG6ZCcisvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipBlock(nn.Module):\n",
        "    def __init__(self, main, skip=None):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(*main)\n",
        "        self.skip = skip if skip else nn.Identity()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.cat([self.main(input), self.skip(input)], dim=1)\n",
        "\n",
        "\n",
        "class FourierFeatures(nn.Module):\n",
        "    def __init__(self, in_features, out_features, std=1.):\n",
        "        super().__init__()\n",
        "        assert out_features % 2 == 0\n",
        "        self.weight = nn.Parameter(torch.randn([out_features // 2, in_features]) * std)\n",
        "\n",
        "    def forward(self, input):\n",
        "        f = 2 * math.pi * input @ self.weight.T\n",
        "        return torch.cat([f.cos(), f.sin()], dim=-1)\n",
        "\n",
        "\n",
        "def expand_to_planes(input, shape):\n",
        "    return input[..., None, None].repeat([1, 1, shape[2], shape[3]])"
      ],
      "metadata": {
        "id": "c2jV9u8ViwHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Diffusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        c = 64  # The base channel count\n",
        "        # The inputs to timestep_embed will approximately fall into the range\n",
        "        # -10 to 10, so use std 0.2 for the Fourier Features.\n",
        "        self.timestep_embed = FourierFeatures(1, 16, std=0.2)\n",
        "        self.net = nn.Sequential(   # 32x32\n",
        "            ResConvBlock(3 + 16 + 4, c, c),\n",
        "            ResConvBlock(c, c, c),\n",
        "            SkipBlock([\n",
        "                nn.AvgPool2d(2),  # 32x32 -> 16x16\n",
        "                ResConvBlock(c, c * 2, c * 2),\n",
        "                ResConvBlock(c * 2, c * 2, c * 2),\n",
        "                SkipBlock([\n",
        "                    nn.AvgPool2d(2),  # 16x16 -> 8x8\n",
        "                    ResConvBlock(c * 2, c * 4, c * 4),\n",
        "                    ResConvBlock(c * 4, c * 4, c * 4),\n",
        "                    SkipBlock([\n",
        "                        nn.AvgPool2d(2),  # 8x8 -> 4x4\n",
        "                        ResConvBlock(c * 4, c * 8, c * 8),\n",
        "                        ResConvBlock(c * 8, c * 8, c * 8),\n",
        "                        ResConvBlock(c * 8, c * 8, c * 8),\n",
        "                        ResConvBlock(c * 8, c * 8, c * 4),\n",
        "                        nn.Upsample(scale_factor=2),\n",
        "                    ]),  # 4x4 -> 8x8\n",
        "                    ResConvBlock(c * 8, c * 4, c * 4),\n",
        "                    ResConvBlock(c * 4, c * 4, c * 2),\n",
        "                    nn.Upsample(scale_factor=2),\n",
        "                ]),  # 8x8 -> 16x16\n",
        "                ResConvBlock(c * 4, c * 2, c * 2),\n",
        "                ResConvBlock(c * 2, c * 2, c),\n",
        "                nn.Upsample(scale_factor=2),\n",
        "            ]),  # 16x16 -> 32x32\n",
        "            ResConvBlock(c * 2, c, c),\n",
        "            ResConvBlock(c, c, 3, dropout_last=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input, log_snrs, cond):\n",
        "        timestep_embed = expand_to_planes(self.timestep_embed(log_snrs[:, None]), input.shape)\n",
        "        b,c,h,w = input.shape\n",
        "        class_embed = torch.zeros(b,4,h,w).to(device)\n",
        "        return self.net(torch.cat([input, class_embed, timestep_embed], dim=1))\n",
        "\n",
        "\n",
        "    def get_features(self, input, log_snrs, cond):\n",
        "        timestep_embed = expand_to_planes(self.timestep_embed(log_snrs[:, None]), input.shape)\n",
        "        b, c, h, w = input.shape\n",
        "        class_embed = torch.zeros(b,4,h,w).to(device)\n",
        "        x = torch.cat([input, class_embed, timestep_embed], dim=1)\n",
        "\n",
        "        features = []\n",
        "        features_before_up = []\n",
        "        res_bl_lvl1_num = 0\n",
        "        for module in self.net:\n",
        "\n",
        "            if isinstance(module, ResConvBlock):\n",
        "                x = module(x)\n",
        "                features.append(x)\n",
        "                res_bl_lvl1_num += 1\n",
        "                if res_bl_lvl1_num == 3:\n",
        "                    features_before_up.append(x)\n",
        "\n",
        "            if isinstance(module, SkipBlock):\n",
        "                before_skip1 = x\n",
        "\n",
        "                for module1 in module.main:\n",
        "\n",
        "                    if isinstance(module1, nn.AvgPool2d):\n",
        "                        x = module1(x)\n",
        "\n",
        "                    if isinstance(module1, ResConvBlock):\n",
        "                        x = module1(x)\n",
        "                        features.append(x)\n",
        "\n",
        "                    if isinstance(module1, SkipBlock):\n",
        "                        before_skip2 = x\n",
        "\n",
        "                        for module2 in module1.main:\n",
        "\n",
        "                            if isinstance(module2, nn.AvgPool2d):\n",
        "                                x = module2(x)\n",
        "\n",
        "                            if isinstance(module2, ResConvBlock):\n",
        "                                x = module2(x)\n",
        "                                features.append(x)\n",
        "\n",
        "                            if isinstance(module2, SkipBlock):\n",
        "                                before_skip3 = x\n",
        "\n",
        "                                for module3 in module2.main:\n",
        "\n",
        "                                    if isinstance(module3, nn.AvgPool2d):\n",
        "                                        x = module3(x)\n",
        "\n",
        "                                    if isinstance(module3, ResConvBlock):\n",
        "                                        x = module3(x)\n",
        "                                        features.append(x)\n",
        "\n",
        "                                    if isinstance(module3, nn.Upsample):\n",
        "                                        features_before_up.append(x)\n",
        "                                        x = module3(x)\n",
        "                                        x = torch.cat([x, before_skip3], dim=1)\n",
        "\n",
        "                            if isinstance(module2, nn.Upsample):\n",
        "                                features_before_up.append(x)\n",
        "                                x = module2(x)\n",
        "                                x = torch.cat([x, before_skip2], dim=1)\n",
        "\n",
        "                    if isinstance(module1, nn.Upsample):\n",
        "                        features_before_up.append(x)\n",
        "                        x = module1(x)\n",
        "                        x = torch.cat([x,before_skip1], dim=1)\n",
        "\n",
        "            if isinstance(module, nn.Upsample):\n",
        "                features_before_up.append(x)\n",
        "                x = module(x)\n",
        "\n",
        "        features = [feature.squeeze().cpu().numpy() for feature in features_before_up]\n",
        "        feature0 = np.array(features[0])\n",
        "        feature1 = np.array(features[1])\n",
        "        feature2 = np.array(features[2])\n",
        "        feature3 = np.array(features[3])\n",
        "        feature0_pooled = F.avg_pool2d(torch.tensor(feature0), kernel_size=4).squeeze()\n",
        "        feature1_pooled = F.avg_pool2d(torch.tensor(feature1), kernel_size=8).squeeze()\n",
        "        feature2_pooled = F.avg_pool2d(torch.tensor(feature2), kernel_size=16).squeeze()\n",
        "        feature3_pooled = F.avg_pool2d(torch.tensor(feature3), kernel_size=32).squeeze()\n",
        "        feature_map = torch.cat((feature0_pooled, feature1_pooled, feature2_pooled, feature3_pooled), axis =1)\n",
        "        return feature_map"
      ],
      "metadata": {
        "id": "9DR14Jaly8FZ",
        "execution": {
          "iopub.status.busy": "2024-03-18T08:48:32.427520Z",
          "iopub.execute_input": "2024-03-18T08:48:32.427912Z",
          "iopub.status.idle": "2024-03-18T08:48:32.467193Z",
          "shell.execute_reply.started": "2024-03-18T08:48:32.427881Z",
          "shell.execute_reply": "2024-03-18T08:48:32.466252Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sample**"
      ],
      "metadata": {
        "id": "xJmrKSq4jRwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_alphas_sigmas(log_snrs):\n",
        "    \"\"\"Returns the scaling factors for the clean image (alpha) and for the\n",
        "    noise (sigma), given the log SNR for a timestep.\"\"\"\n",
        "    return log_snrs.sigmoid().sqrt(), log_snrs.neg().sigmoid().sqrt()\n",
        "\n",
        "def get_ddpm_schedule(t):\n",
        "    \"\"\"Returns log SNRs for the noise schedule from the DDPM paper.\"\"\"\n",
        "    return -torch.special.expm1(1e-4 + 10 * t**2).log()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, x, steps, eta, classes):\n",
        "    \"\"\"Draws samples from a model given starting noise.\"\"\"\n",
        "    ts = x.new_ones([x.shape[0]])\n",
        "\n",
        "    # Create the noise schedule\n",
        "    t = torch.linspace(1, 0, steps + 1)[:-1]\n",
        "    log_snrs = get_ddpm_schedule(t)\n",
        "    alphas, sigmas = get_alphas_sigmas(log_snrs)\n",
        "\n",
        "    # The sampling loop\n",
        "    for i in trange(steps):\n",
        "\n",
        "        # Get the model output (v, the predicted velocity)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            v = model(x, ts * log_snrs[i], classes).float()\n",
        "\n",
        "        # Predict the noise and the denoised image\n",
        "        pred = x * alphas[i] - v * sigmas[i]\n",
        "        eps = x * sigmas[i] + v * alphas[i]\n",
        "\n",
        "        # If we are not on the last timestep, compute the noisy image for the\n",
        "        # next timestep.\n",
        "        if i < steps - 1:\n",
        "            # If eta > 0, adjust the scaling factor for the predicted noise\n",
        "            # downward according to the amount of additional noise to add\n",
        "            ddim_sigma = eta * (sigmas[i + 1]**2 / sigmas[i]**2).sqrt() * \\\n",
        "                (1 - alphas[i]**2 / alphas[i + 1]**2).sqrt()\n",
        "            adjusted_sigma = (sigmas[i + 1]**2 - ddim_sigma**2).sqrt()\n",
        "            # Recombine the predicted noise and predicted denoised image in the\n",
        "            # correct proportions for the next step\n",
        "            x = pred * alphas[i + 1] + eps * adjusted_sigma\n",
        "            # Add the correct amount of fresh noise\n",
        "            if eta:\n",
        "                x += torch.randn_like(x) * ddim_sigma\n",
        "    # If we are on the last timestep, output the denoised image\n",
        "    return pred"
      ],
      "metadata": {
        "id": "jpy3GC7XzC7J",
        "execution": {
          "iopub.status.busy": "2024-03-18T08:48:33.683464Z",
          "iopub.execute_input": "2024-03-18T08:48:33.683837Z",
          "iopub.status.idle": "2024-03-18T08:48:33.694539Z",
          "shell.execute_reply.started": "2024-03-18T08:48:33.683810Z",
          "shell.execute_reply": "2024-03-18T08:48:33.693726Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Noise schedule**"
      ],
      "metadata": {
        "id": "My098Q8nyeKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "t_vis = torch.linspace(0, 1, 1000)\n",
        "log_snrs_vis = get_ddpm_schedule(t_vis)\n",
        "alphas_vis, sigmas_vis = get_alphas_sigmas(log_snrs_vis)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "axes[0].plot(t_vis, alphas_vis, label='alpha (signal level)')\n",
        "axes[0].plot(t_vis, sigmas_vis, label='sigma (noise level)')\n",
        "axes[0].legend()\n",
        "axes[0].set_xlabel('timestep')\n",
        "axes[0].grid()\n",
        "\n",
        "axes[1].plot(t_vis, log_snrs_vis, label='log SNR')\n",
        "axes[1].legend()\n",
        "axes[1].set_xlabel('timestep')\n",
        "axes[1].grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TYdls2GREKLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset**"
      ],
      "metadata": {
        "id": "UjoakNfmj48U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# tf = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.5], [0.5]),\n",
        "# ])\n",
        "\n",
        "tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "\n",
        "train_set = datasets.CIFAR100('data', train=True, download=True, transform=tf)\n",
        "val_set = datasets.CIFAR100('data', train=False, download=True, transform=tf)\n",
        "\n",
        "train_dl = data.DataLoader(train_set, batch_size, shuffle=True, num_workers=4, persistent_workers=True, pin_memory=True)\n",
        "val_dl = data.DataLoader(val_set, batch_size, num_workers=4, persistent_workers=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "OMWkwqn6zSZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define parameters**"
      ],
      "metadata": {
        "id": "KYO5otQ0kNJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "epoch = 0\n",
        "ema_decay = 0.998\n",
        "\n",
        "# The number of timesteps to use when sampling\n",
        "steps = 500\n",
        "\n",
        "# The amount of noise to add each timestep when sampling\n",
        "# 0 = no noise (DDIM)\n",
        "# 1 = full noise (DDPM)\n",
        "eta = 1.\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "model = Diffusion().to(device)\n",
        "model_ema = deepcopy(model)\n",
        "print('Model parameters:', sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "id": "egOFiEQ_zL25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Use a low discrepancy quasi-random sequence to sample uniformly distributed\n",
        "# timesteps. This considerably reduces the between-batch variance of the loss.\n",
        "rng = torch.quasirandom.SobolEngine(1, scramble=True)"
      ],
      "metadata": {
        "id": "03wppdUmwoIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "kZ3Zp4eXkR6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_loss(model, rng, reals, classes):\n",
        "    # Draw uniformly distributed continuous timesteps\n",
        "    t = rng.draw(reals.shape[0])[:, 0].to(device)\n",
        "\n",
        "    # Calculate the noise schedule parameters for those timesteps\n",
        "    log_snrs = get_ddpm_schedule(t)\n",
        "    alphas, sigmas = get_alphas_sigmas(log_snrs)\n",
        "    weights = log_snrs.exp() / log_snrs.exp().add(1)\n",
        "\n",
        "    # Combine the ground truth images and the noise\n",
        "    alphas = alphas[:, None, None, None]\n",
        "    sigmas = sigmas[:, None, None, None]\n",
        "    noise = torch.randn_like(reals)\n",
        "    noised_reals = reals * alphas + noise * sigmas\n",
        "    targets = noise * alphas - reals * sigmas\n",
        "\n",
        "    # Compute the model output and the loss.\n",
        "    with torch.cuda.amp.autocast():\n",
        "        v = model(noised_reals, log_snrs, classes)\n",
        "        return (v - targets).pow(2).mean([1, 2, 3]).mul(weights).mean()\n",
        "\n",
        "\n",
        "def train():\n",
        "    for i, (reals, classes) in enumerate(tqdm(train_dl)):\n",
        "        opt.zero_grad()\n",
        "        reals = reals.to(device)\n",
        "        classes = classes.to(device)\n",
        "\n",
        "        # Evaluate the loss\n",
        "        loss = eval_loss(model, rng, reals, classes)\n",
        "\n",
        "        # Do the optimizer step and EMA update\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        ema_update(model, model_ema, 0.95 if epoch < 20 else ema_decay)\n",
        "        scaler.update()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            tqdm.write(f'Epoch: {epoch}, iteration: {i}, loss: {loss.item():g}')\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "@torch.random.fork_rng()\n",
        "@eval_mode(model_ema)\n",
        "def val():\n",
        "    tqdm.write('\\nValidating...')\n",
        "    torch.manual_seed(seed)\n",
        "    rng = torch.quasirandom.SobolEngine(1, scramble=True)\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    for i, (reals, classes) in enumerate(tqdm(val_dl)):\n",
        "        reals = reals.to(device)\n",
        "        classes = classes.to(device)\n",
        "\n",
        "        loss = eval_loss(model_ema, rng, reals, classes)\n",
        "\n",
        "        total_loss += loss.item() * len(reals)\n",
        "        count += len(reals)\n",
        "    loss = total_loss / count\n",
        "    tqdm.write(f'Validation: Epoch: {epoch}, loss: {loss:g}')\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "@torch.random.fork_rng()\n",
        "@eval_mode(model_ema)\n",
        "def demo():\n",
        "    tqdm.write('\\nSampling...')\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    noise = torch.randn([100, 3, 32, 32], device=device)\n",
        "    fakes_classes = torch.arange(10, device=device).repeat_interleave(10, 0)\n",
        "    fakes = sample(model_ema, noise, steps, eta, fakes_classes)\n",
        "\n",
        "    grid = utils.make_grid(fakes, 10).cpu()\n",
        "    filename = f'demo_{epoch:05}.png'\n",
        "    TF.to_pil_image(grid.add(1).div(2).clamp(0, 1)).save(filename)\n",
        "    display.display(display.Image(filename))\n",
        "    tqdm.write('')\n",
        "\n",
        "\n",
        "def save():\n",
        "    filename = 'cifar_diffusion.pth'\n",
        "    obj = {\n",
        "        'model': model.state_dict(),\n",
        "        'model_ema': model_ema.state_dict(),\n",
        "        'opt': opt.state_dict(),\n",
        "        'scaler': scaler.state_dict(),\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    torch.save(obj, filename)\n",
        "\n",
        "\n",
        "try:\n",
        "    val()\n",
        "    demo()\n",
        "    while True:\n",
        "        print('Epoch', epoch)\n",
        "        train()\n",
        "        epoch += 1\n",
        "        if epoch % 5 == 0:\n",
        "            val()\n",
        "            demo()\n",
        "        save()\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ],
      "metadata": {
        "id": "blNYA6yzzuXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save model**"
      ],
      "metadata": {
        "id": "8wHyrWzjw2yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WMg9EYCN3Ehy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_path = '/content/cifar_diffusion.pth'\n",
        "destination_path = '/content/drive/MyDrive/cifar100_diffusion.pth'\n",
        "\n",
        "shutil.copyfile(source_path, destination_path)"
      ],
      "metadata": {
        "id": "lrSfthGew9jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load model**"
      ],
      "metadata": {
        "id": "8fndPVr2Yxky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "3a8ay6xm8Qpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '1GJy9fHFPEt3acuAcV0syubKJOeCZaWnv' # URL id\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('cifar100_diffusion.pth')"
      ],
      "metadata": {
        "id": "a5GZlD3O8Xoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "weights_path = '/content/cifar100_diffusion.pth'\n",
        "saved_obj = torch.load(weights_path, map_location=torch.device('cpu'))\n",
        "model_dif = Diffusion().to(device)\n",
        "model_dif.load_state_dict(saved_obj['model'])"
      ],
      "metadata": {
        "id": "nnkNVF1d8au_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print('Using device:', device)\n",
        "\n",
        "# torch.manual_seed(0)\n",
        "\n",
        "# weights_path = '/content/drive/MyDrive/cifar100_diffusion.pth'\n",
        "# saved_obj = torch.load(weights_path, map_location=torch.device('cpu'))\n",
        "# model_dif = Diffusion().to(device)\n",
        "# model_dif.load_state_dict(saved_obj['model'])"
      ],
      "metadata": {
        "id": "xgL4BfjAYzrr",
        "execution": {
          "iopub.status.busy": "2024-03-18T09:05:20.439234Z",
          "iopub.execute_input": "2024-03-18T09:05:20.440028Z",
          "iopub.status.idle": "2024-03-18T09:05:25.042953Z",
          "shell.execute_reply.started": "2024-03-18T09:05:20.439996Z",
          "shell.execute_reply": "2024-03-18T09:05:25.042054Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Umap feature vizualization**"
      ],
      "metadata": {
        "id": "pFaru2PiCkje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "fpzF5ay3qcWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import umap\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "metadata": {
        "id": "pSDPnMQVqfDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_BNJZD37ufd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "\n",
        "dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "sampler = SubsetRandomSampler(range(10000))\n",
        "dataloader_small = DataLoader(dataset, batch_size=1000, sampler=sampler)\n",
        "\n",
        "model_dif.eval()\n",
        "model_dif.to(device)\n",
        "\n",
        "features_list = []\n",
        "labels_list = []\n",
        "\n",
        "for images, labels in dataloader_small:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    t_up = torch.tensor([0.001] * len(labels)).to(device)\n",
        "    log_snrs = get_ddpm_schedule(t_up)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_snrs = log_snrs.to(device)\n",
        "        features = model_dif.get_features(images, log_snrs, labels).to(device)\n",
        "\n",
        "    features_list.append(features.cpu().detach().numpy())\n",
        "    labels_list.append(labels.cpu().detach().numpy())\n",
        "\n",
        "features_array = np.concatenate(features_list, axis=0)\n",
        "labels_array = np.concatenate(labels_list, axis=0)"
      ],
      "metadata": {
        "id": "MeyUST_yqceY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_array.shape"
      ],
      "metadata": {
        "id": "8saBkEfsAgTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(features_array)\n",
        "\n",
        "reducer = umap.UMAP(n_components=2, random_state=1)\n",
        "X_umap = reducer.fit_transform(X_scaled)"
      ],
      "metadata": {
        "id": "wEKcQmq498LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['#0d0887',\n",
        " '#46039f',\n",
        " '#7201a8',\n",
        " '#9c179e',\n",
        " '#bd3786',\n",
        " '#d8576b',\n",
        " '#ed7953',\n",
        " '#fb9f3a',\n",
        " '#fdca26',\n",
        " '#f0f921']\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "for i in range(10):\n",
        "    plt.scatter(X_umap[labels_array == i, 0], X_umap[labels_array == i, 1], color=colors[i], label=str(i), s=10)\n",
        "plt.xlabel('UMAP Component 1', fontsize=14)\n",
        "plt.ylabel('UMAP Component 2', fontsize=14)\n",
        "plt.title('2D Projection of diffusion Features using UMAP', fontsize=16)\n",
        "plt.legend(title='Digit', loc='upper right')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.savefig('umap_projection.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s8nmd2hb9_UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('x_umap', np.array(X_umap))"
      ],
      "metadata": {
        "id": "kFdhryhx-Ge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('labels_array', np.array(labels_array))"
      ],
      "metadata": {
        "id": "Da9rcQYP-JtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3D-projection**"
      ],
      "metadata": {
        "id": "FBmODsrErCXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reducer = umap.UMAP(n_components=3, n_neighbors=15, min_dist=0.1, random_state=42)\n",
        "features_3d = reducer.fit_transform(features_array)\n",
        "\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "for i in range(10):\n",
        "    plt.scatter(X_umap[labels_array == i, 0], X_umap[labels_array == i, 1], color=colors[i], label=str(i), s=5)\n",
        "\n",
        "ax.set_xlabel('UMAP Component 1', fontsize=14)\n",
        "ax.set_ylabel('UMAP Component 2', fontsize=14)\n",
        "ax.set_zlabel('UMAP Component 3', fontsize=14)\n",
        "\n",
        "ax.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.savefig('umap_3d_projection_mnist.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1cAe8UGyFAJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('features_3d', np.array(features_3d))\n",
        "np.save('labels_array', np.array(labels_array))"
      ],
      "metadata": {
        "id": "jIC-aHsnFSds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Small Net training**"
      ],
      "metadata": {
        "id": "tNVniM7Vp0uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(images, labels, t_up, batch_size, model_dif):\n",
        "    \"\"\"\n",
        "    Extracts features, namely concatenates averaged arrays from different layers of the diffusion model with the UNet architecture.\n",
        "    :t_up: from which step of the forward diffusion process image is needed.\n",
        "    :model_dif: a diffusion model.\n",
        "    :forward_diffusion: forward diffusion process.\n",
        "    :return: a tensor of shape [batch_size, 80].\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        t = torch.tensor([t_up] * labels.shape[0])\n",
        "        log_snrs = get_ddpm_schedule(t)\n",
        "        log_snrs = log_snrs.to(device)\n",
        "        alphas, sigmas = get_alphas_sigmas(log_snrs)\n",
        "        weights = log_snrs.exp() / log_snrs.exp().add(1)\n",
        "        alphas = alphas[:, None, None, None]\n",
        "        sigmas = sigmas[:, None, None, None]\n",
        "        noise = torch.randn_like(images)\n",
        "        noised_reals = images * alphas + noise * sigmas\n",
        "        features = model_dif.get_features(noised_reals.to(device), log_snrs, labels)\n",
        "    return torch.tensor(features)"
      ],
      "metadata": {
        "id": "1IptJhjRoIcp",
        "execution": {
          "iopub.status.busy": "2024-03-18T09:11:16.702462Z",
          "iopub.execute_input": "2024-03-18T09:11:16.702873Z",
          "iopub.status.idle": "2024-03-18T09:11:16.712139Z",
          "shell.execute_reply.started": "2024-03-18T09:11:16.702844Z",
          "shell.execute_reply": "2024-03-18T09:11:16.711064Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader, t_up, batch_size, model, criterion, optimizer, model_dif,  epochs=90, loss_list=[]):\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            features = extract_features(images, labels, t_up, batch_size, model_dif.to(device)).to(device)\n",
        "            outputs = model(features)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        loss_list.append(running_loss / len(train_loader))\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.3f}\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "def test_model(model, test_loader, t_up, batch_size, model_dif=model_dif):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            features = extract_features(images, labels, t_up, batch_size, model_dif).to(device)\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "GZ4NhxpRpuFo",
        "execution": {
          "iopub.status.busy": "2024-03-18T09:11:17.927862Z",
          "iopub.execute_input": "2024-03-18T09:11:17.928233Z",
          "iopub.status.idle": "2024-03-18T09:11:17.936526Z",
          "shell.execute_reply.started": "2024-03-18T09:11:17.928205Z",
          "shell.execute_reply": "2024-03-18T09:11:17.935504Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "n_samples = 16\n",
        "batch_size = 4\n",
        "n_classes = 100\n",
        "\n",
        "class_indices = [[] for _ in range(n_classes)]\n",
        "for idx, (_, label) in enumerate(train_dataset):\n",
        "    class_indices[label].append(idx)\n",
        "\n",
        "selected_indices = []\n",
        "for indices in class_indices:\n",
        "    selected_indices.extend(indices[:n_samples])\n",
        "\n",
        "sampler = SubsetRandomSampler(selected_indices)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "U16Gh3Ub3Ym3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(dataset, num_train_per_class):\n",
        "    train_indices = []\n",
        "    for i in range(100):\n",
        "        indices = torch.where(torch.tensor(dataset.targets) == i)[0].tolist()\n",
        "        train_indices.extend(indices[:num_train_per_class])\n",
        "    return train_indices\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, hidden_dim=128):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.input_size = input_size\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "ytINstvOF_RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from smallnet import LinearNet, Net, split_dataset\n",
        "\n",
        "input_size = 512"
      ],
      "metadata": {
        "id": "Lj0G6TWDqmv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "#t_ups = [0.01, 0.03, 0.05, 0.1, 0.3, 0.45, 0.55, 1]\n",
        "t_ups = [0.01, 0.03, 0.05, 0.07, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 0.99]\n",
        "\n",
        "\n",
        "accuracies = {}\n",
        "for t_up in t_ups:\n",
        "    print(f'--------- CALCULATIONS FOR t_up={t_up} ---------')\n",
        "    accuracies[t_up] = []\n",
        "\n",
        "    for i in range(1, 6):\n",
        "        print(f'------ calc N=#{i} ------')\n",
        "\n",
        "        model = Net(input_size, n_classes).to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        loss_list = train_model(train_loader, t_up, batch_size, model, criterion, optimizer, model_dif, epochs=epochs)\n",
        "        accuracy = test_model(model, test_loader, t_up, batch_size, model_dif=model_dif)\n",
        "        print(f'accuracy = {accuracy}%')\n",
        "        accuracies[t_up].append(accuracy)\n",
        "\n",
        "    print(f'for {t_up}, accuracies=[' + ', '.join(list(map(str, accuracies[t_up]))) + ']')\n"
      ],
      "metadata": {
        "id": "__5-salBzDQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies"
      ],
      "metadata": {
        "id": "TDBqa8RoSnvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54_NcfKyOMPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "accuracy = {k: v for k, v in accuracies.items() if k not in [0.99, 0.46, 0.48, 0.52, 0.54, 0.06]}\n",
        "\n",
        "accuracy_transformed = {int(k * 1000): v for k, v in accuracy.items()}\n",
        "sorted_accuracy = dict(sorted(accuracy_transformed.items()))\n",
        "\n",
        "t_up_values = list(sorted_accuracy.keys())\n",
        "means = [np.mean(sorted_accuracy[t_up]) for t_up in t_up_values]\n",
        "variances = [np.var(sorted_accuracy[t_up]) for t_up in t_up_values]\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(t_up_values, means, marker='o', linestyle='-', color='blue', markersize=8, markerfacecolor='red')\n",
        "plt.fill_between(t_up_values, np.array(means) - np.array(variances), np.array(means) + np.array(variances), color='blue', alpha=0.2)\n",
        "\n",
        "plt.axvline(x=50, color='black')\n",
        "plt.text(110, 25, r'$t_{opt} = 50$', fontsize=12, verticalalignment='bottom', horizontalalignment='center', fontweight='heavy')\n",
        "\n",
        "plt.xticks(t_up_values, t_up_values, rotation=45, fontsize=9)\n",
        "plt.xlabel('t_up')\n",
        "plt.ylabel('Mean Accuracy on test, %')\n",
        "plt.title('Optimal timestep selection for CIFAR-100')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HoGkIy3qzDfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAq6FaIIIZxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTQCBGhwYKHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset size varying"
      ],
      "metadata": {
        "id": "XtODtcfiaiBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "xvF1IqE5X8UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORKERS = 0\n",
        "\n",
        "tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n",
        "])\n",
        "train_dataset = datasets.CIFAR100('data', train=True, download=True, transform=tf)\n",
        "test_dataset = datasets.CIFAR100('data', train=False, download=True, transform=tf)\n",
        "accuracy_list = list()\n",
        "# TRAIN_CLASS_SIZE_list = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
        "# BATCH_SIZE_list =       [2, 4, 8, 16, 32, 64, 128, 128, 128, 128]\n",
        "# TRAIN_CLASS_SIZE_list = [16, 32, 64, 128, 256, 512, 1024]\n",
        "# BATCH_SIZE_list =       [16, 32, 64, 128, 128, 128, 128]\n",
        "TRAIN_CLASS_SIZE_list = [256]\n",
        "BATCH_SIZE_list =       [128]\n",
        "for i in range(len(TRAIN_CLASS_SIZE_list)):\n",
        "    print(\"____________________________________________\")\n",
        "    print(\"train class size:\", TRAIN_CLASS_SIZE_list[i])\n",
        "\n",
        "    BATCH_SIZE = BATCH_SIZE_list[i] #128\n",
        "    TRAIN_CLASS_SIZE = TRAIN_CLASS_SIZE_list[i]\n",
        "\n",
        "    #train_dataset = datasets.MNIST('data', train=True, download=True, transform=tf)\n",
        "\n",
        "    train_indices = split(train_dataset, num_train_per_class=TRAIN_CLASS_SIZE)\n",
        "    train_subset = Subset(train_dataset, train_indices)\n",
        "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "    #test_dataset = datasets.MNIST('data', train=False, download=True, transform=tf)\n",
        "\n",
        "    test_subset = test_dataset\n",
        "    test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE)\n",
        "    # print(len(train_loader))\n",
        "    #from smallnet import LinearNet, Net, split_dataset\n",
        "    input_size = 512  # embedding size\n",
        "    num_classes = 100\n",
        "    epochs = 100\n",
        "    t_up = 0.05  # from 0 to 1!!!\n",
        "    model = Net(input_size, num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    loss_list = train_model(train_loader, t_up, BATCH_SIZE, model, criterion, optimizer, model_dif, epochs=epochs)\n",
        "    accuracy = test_model(model, test_loader, t_up, BATCH_SIZE, model_dif=model_dif)\n",
        "    print(accuracy)\n",
        "    accuracy_list.append(accuracy)"
      ],
      "metadata": {
        "id": "yh5shR5OGCmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMjQjX3Qa6C-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}